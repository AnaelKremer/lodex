append = pack
label = query-openalex
extension = json
mimeType = application/json

# load some plugins to activate some statements
[use]
plugin = conditor
plugin = basics
plugin = analytics

# Toggle ezs traces (see server stderr log)
[debug]
ezs = true

# {{{
[TXTConcat]

[env]
path = url
value = https://api.openalex.org/works

path = query
value = self().trim()

[replace]
path = filter
value = env('query')

path = cursor
value = *

[URLRequest]
timeout = 60000
url = env('url')

[loop]
test = has('meta.next_cursor')
test = get('meta.next_cursor').isNull().thru(x=>!x)

[loop/replace]
path = filter
value = env('query')

path = cursor
value = get('meta.next_cursor')

[loop/URLRequest]
url = env('url')
timeout = 60000

[loop/drop]
path = meta.next_cursor

[exploding]
value = results

[exchange]
value = get('value')

[assign]
path = uri
value = get('id').replace('https://openalex.org/', '')

path = doi
value = get('doi').replace("https://doi.org/","").toLower()

path = isOa
value = get("open_access.is_oa")

# On teste si la liste des urls où sont déposés les "works" au moins une appartient à un portail Hal.
# La regex couvre l'ensemble des portails hal et la spécificité de leurs urls.
[assign]
path = isHal
value = get("locations").map("landing_page_url").compact().some(item=>(/[^a-zA-Z0-9]hal[^a-zA-Z0-9]/).test(item))

# On récupère le champ qui indique dans quelles bases les "works" sont indexés.
# On concatène le champ "isHal", on retire les false et transforme les true en "hal"
[assign]
path = indexedIn
value = get("indexed_in").concat(self.isHal).pull(false).map(item=>item === true ? "hal" : item).sort()

[assign]
path = authorName
value = get('authorships').flatMap("raw_author_name")

[assign]
path = institutions
value = get('authorships').flatMap("raw_affiliation_strings")

# On récupère l'éditeur de la revue. ([] si vide, nécéssaire pour les instructions et fonctions futures).
[assign]
path = publisherOnly
value = get("primary_location.source.host_organization_name","n/a")

# On récupère un tableau avec l'éditeur mais aussi, s'il en a, sa ou ses sociétés mères (3 niveaux de hiérarchie).
# L'ordre est aléatoire, on ne peut se baser sur l'index. (["n/a"] si vide, nécéssaire pour les instructions et fonctions futures).
[assign]
path = linkedPublishers
value = get("primary_location.source.host_organization_lineage_names",["n/a"])

# On compare les 2 champ créés au-dessus, pour retirer du tableau les éditeurs du plus-bas niveau de hiérarchie.
# Si publisherOnly était au plus haut niveau (0) on obtient [].
# S'il était au niveau 1 on obtient son niveau supérieur (0).
# S'il était au plus bas on obtient ses 2 sociétés mères (0 & 1).
[assign]
path = xorPublisher
value = get("publisherOnly").castArray().xor(self.linkedPublishers)

# On isole tous les tableaux vides.
[swing]
test = get("xorPublisher").isEmpty()

# On leur réattribue leur unique valeur.
[swing/assign]
path = xorPublisher
value = get("publisherOnly")

# On associe le tout, ne reste plus que le cas des tableaux avec niveaux 0 et 1.
# On retire les parents directs des éditeurs de niveau 2, on n'a donc plus que les éditeurs du plus haut niveau.
[assign]
path = publisher
value = get("xorPublisher").pull("Springer Science+Business Media","Vandenhoeck & Ruprecht","University of California, Berkeley","University of California, Los Angeles","Siberian Branch of the Russian Academy of Sciences").toString().replace(null,"n/a").replace(undefined,"n/a")

# On recupère l'abstract sous forme d'un tableau d'objets où keys sont les mots et values leur(s) position(s) dans l'abstract.
# Les keys contiennent donc des "." ou autres caractères spéciaux proscrits MongoDB Node.js driver.
# On transforme cela en un tableau où chaque value est "key:value", on découpe pour avoir une matrice. On parse les values en base 10 pour obtenir des entiers.
# On inverse ensuite les éléments dans chaque sous-tableau de la matrice. On effectue un tri dans la matrice, on ne garde plus que les mots et transforme le tout en un string.
[assign]
path = abstract
value = get("abstract_inverted_index").flatMap((values, key) => {return values.map(value => `${key}:${value}`) }).map(item => item.split(":")).map(([first, second]) => [first, parseInt(second, 10)]).map(item => item.reverse()).sort((a, b) => a[0] - b[0]).map(item => item.slice(1)).flatMap().join(' ')

[exchange]
value = omit(["abstract_inverted_index","indexed_in","display_name","publisherOnly","xorPublisher"])

# }}}

# Ensures that each object contains an identification key (required by lodex)
[swing]
test = pick(['URI', 'uri']).pickBy(_.identity).isEmpty()
[swing/identify]

# Ignore objects with duplicate URI
[dedupe]
ignore = true

# Prevent keys from containing dot path notation (which is forbidden by nodejs mongoDB driver)
[OBJFlatten]
separator = fix('.')
reverse = true
safe = true

# Uncomment to see each data sent to the database
#[debug]

# Add contextual metadata related to the import
[assign]
path = lodexStamp.importedDate
value = fix(new Date()).thru(d => d.toDateString())
path = lodexStamp.usedParser
value = env('parser')
path = lodexStamp.query
value = env('query')
path = uri
value = get('uri').trim()
